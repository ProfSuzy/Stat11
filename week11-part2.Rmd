---
title: "Introducing common statistical methods"
subtitle: "Class 20"
author: "STAT 11 with Prof. Suzy"
institute: "Swarthmore College"
date: "11/18/21 (updated: `r Sys.Date()`)"
output:
  #   css: ["default", "assets/sydney-fonts.css", "assets/sydney.css"]
  xaringan::moon_reader:
  self_contained: false # if true, fonts will be stored locally
#    includes:
#     in_header: "assets/mathjax-equation-numbers.html"
nature:
  #      beforeInit: ["assets/remark-zoom.js", "https://platform.twitter.com/widgets.js"]
  highlightStyle: github
highlightLines: true
countIncrementalSlides: false
ratio: '16:9' # alternatives '16:9' or '4:3' or others e.g. 13:9
navigation:
  scroll: false # disable slide transitions by scrolling
includes:
  in_header: mystyles.sty
header-includes:
  - usepackage{xcolor}
---
  

```{r setup_pres, include=FALSE, echo=FALSE}
#devtools::install_github("ropenscilabs/icon")
#devtools::session_info('rmarkdown')


# knitr settings to control how R chunks work.
require(knitr)
opts_chunk$set(
  tidy = FALSE, # display code as typed
  size = "small" # slightly smaller font for code
)

knitr::opts_chunk$set(message = FALSE) # include this if you don't want markdown to knit messages
knitr::opts_chunk$set(warning = FALSE) # include this if you don't want markdown to knit warnings

rm(list=ls())
library(tidyverse)
#library('gridExtra')
#library(broom)
data <- read_csv("~/Documents/global_wealth_and_health.csv")
data2 <- data  %>% filter(!is.na(Value)) %>% 
               filter(Time=="2018") %>% 
               select(-c('Flag Codes', Flags, LOCATION, TIME, Time, DEMO_IND)) 
data3 <- pivot_wider(data2, id_cols=Country, names_from = Indicator, values_from = Value)
global_wealth_and_health <- data3[,-c(4,9,13)]
colnames(global_wealth_and_health) = c("Country", "FertRate", "LifeExpect", "MortRate", 
      "HIVPrev", "RuralPop", "GDP", "TotalExpenditure", "TotalPop", "SrPop", "YoungPop", "PovertyCount")
```

```{css, echo=FALSE}
pre {
  background: #FFBB33;
  max-width: 100%;
  overflow-x: scroll;
}

.scroll-output {
  height: 60%;
  overflow-y: scroll;
}

.scroll-small {
  height: 50%;
  overflow-y: scroll;
}
   
.red{color: #ce151e;}
.green{color: #26b421;}
.blue{color: #426EF0;}
```
     
## Today 

1. Key concepts and inference for categorical variables

2. Group work on HW 7 Problem 1 

3. The math and coding details for inference about means and proportions 

4. Looking ahead  

---
## Key concepts 
### Statistical inference 

* The sampling distribution of the sample mean (or sample proportion) is a hypothetical distribution based on the idea of repeatedly obtaining a random sample from the population of interest. 

* Statistical inference requires us to have a larger population in mind.  

* The scope of the conclusions always depends on the quality of the data and the design of the study. Garbage in means garbage out, from the most basic to the most advanced statistical methods.   


---
## Inference for categorical variables  
## Chi-square procedures

* **Test of independence**: does the data suggest that one variable may be associated with another? 

--
* **Test of homogeneity**: are the different possible outcomes of a variable equally likely? 

--
* **Goodness-of-fit**: does a hypothesized probability distribution fit your data well?



---
## Group work
### HW 7 Problem 1 

**Instructions:** With this additional information, spend another $15$ minutes working with your group to answer *all* of the questions on the worksheet for Class 19. 

As I walk around, feel free to ask me questions. I may listen in to your group discussion for a bit to guide your discussions. 

<br> 

<br> 

**Hint:** There may not be any parameters for some of the chi-squared tests! 

---
## Inference for means and proportions 
## When to use the t-distribution or the Normal distribution 

* For inference about proportions, always use the Normal distribution (but make sure you have enough observed "success" and "failures"!).

* For inference about means, if the sample size is large, use the Normal distribution. .blue[(Or use the t-distribution because they're essentially the same at this point!)]

* For inference about means, if the sample size is small, use the t-distribution. 

<br> 
--
Side note: In practice, there are sometimes alternate ways to conduct inference on differences of means or proportions when there are two populations under consideration. 


---
## Inference for a single feature of the same population 
### Proportions: One sample Z test and CI 

$$H_0: p = p_0; \quad H_A:  \begin{cases} p \neq p_0 \\ p \leq p_0 \\  p \geq p_0 \end{cases}$$


$$T.S. = \frac{\hat{p}_{obs} - p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}}\hspace{.5cm} \widetilde{\tiny H_{0}}  \hspace{.5cm}  N(0,1)$$
--
```{r}
#prop.test(x=?, n=?, p=?, alternative = "?")
```


---
## Inference for a single feature of the same population 
### Proportions: One sample Z test and CI 

A $(1-\alpha)\times 100\%$ CI for an unknown proportion, $p$, is 
$$\hat{p}_{obs} \pm \left( z_{\alpha/2} \times \sqrt{\frac{\hat{p}_{obs}(1-\hat{p}_{obs})}{n}}\right),$$
where $z_{\alpha/2}$ is the lower $\alpha/2^{th}$ quantile of a $N(0,1)$ distribution. 

--
```{r}
#prop.test(x=?, n=?, conf.level = 1-alpha)
```

---
## Inference for a single feature of the same population 
### Means: One sample t test and CI 

$$H_0: \mu = \mu_0; \quad H_A:  \begin{cases} \mu \neq \mu_0 \\ \mu \leq \mu_0 \\  \mu \geq \mu_0 \end{cases}$$

$$T.S. = \frac{\bar{X} - \mu_0}{\sqrt{\frac{s^2}{n}}} \hspace{.2cm} \widetilde{\tiny H_{0}} \hspace{.2cm} t_{(n-1)}.$$

--
```{r}
#t.test(x = vector_of_data_values, alternative = "?", mu = ?)
```

---
## Inference for a single feature of the same population 
### Means: One sample t test and CI 

A $(1-\alpha)\times 100\%$ CI for an unknown mean, $\mu$, is 
$$\bar{x}_{obs} \pm \left(t^*_{\alpha/2} \times \sqrt{\frac{s^2_{obs}}{n}}\right),$$
where $t^*_{\alpha/2}$ is the lower $\alpha/2^{th}$ quantile of a $t_{(n-1)}$ distribution. 

--
```{r}
#t.test(x = vector_of_data_values, conf.level = ?)
```

---
## Inference for a single feature of the same population 
### Means: One sample t test and CI 

.scroll-output[
**Note:** Because the input must be a vector of observed data values, we must specifically extract these variables from our data object (`tibble`) using the dollar sign: 
```{r}
mytibble = tibble(varb1 = rnorm(5), varb2 = rt(5, df=2))
mytibble$varb1 
```

Hence a t-test for the mean of the population from whence we obtained `varb1` may be
```{r}
t.test(x = mytibble$varb1, mu=0, conf.level = 0.98)
```
]


---
## Inference for a single feature of two independent populations 
### Proportions: Two sample Z test and CI 

$$H_0: p\color{blue}{_1 - p_2} = \color{blue}{0}; \quad H_A:  \begin{cases} p\color{blue}{_1 - p_2} \neq \color{blue}{0} \\ p\color{blue}{_1 - p_2} \leq \color{blue}{0} \\  p\color{blue}{_1 - p_2} \geq \color{blue}{0} \end{cases}$$


$$T.S. = \frac{\hat{p}\color{blue}{_1 - \hat{p}_2} - \color{blue}{0}}{\sqrt{p\color{blue}{_{pool}}(1-p\color{blue}{_{pool}})\color{blue}{\frac{1}{n_1}  + \frac{1}{n_2}}}}\hspace{.5cm} \widetilde{\tiny H_{0}}  \hspace{.5cm}  N(0,1),$$
where $p_{pool} = \frac{\text{total number of observed successes}}{n_1 + n_2}.$

--
```{r}
#prop.test(x=c(number_of_successes_pop1, number_of_successes_pop2), n=c(n1, n2), alternative = "?")
```

---
## Inference for a single feature of two independent populations 
### Proportions: Two sample Z test and CI 

A $(1-\alpha)\times 100\%$ CI for an unknown proportion, $p$, is 
$$\hat{p}_{obs\color{blue}{,1}} - \color{blue}{\hat{p}_2} \pm \left( z_{\alpha/2}^* \times \sqrt{ \color{blue}{ \frac{\hat{p}_{obs,1}(1-\hat{p}_{obs,1})}{n_1} + \frac{\hat{p}_{obs,2}(1-\hat{p}_{obs,2})}{n_2}  } }\right),$$
where $z_{\alpha/2}^*$ is the lower $\alpha/2^{th}$ quantile of a $N(0,1)$ distribution. 

--
```{r}
#prop.test(x=c(number_of_successes_pop1, number_of_successes_pop2), n=c(n1, n2), conf.level = ?)
```

---
## Inference for a single feature of two independent populations 
### Means: Two sample t test and CI 


$$H_0: \mu\color{blue}{_1 - \mu_2} = \color{blue}{0} \quad H_A:  \begin{cases} \mu\color{blue}{_1 - \mu_2} \neq \color{blue}{0} \\ \mu\color{blue}{_1 - \mu_2} \leq \color{blue}{0} \\  \mu\color{blue}{_1 - \mu_2} \geq \color{blue}{0} \end{cases}$$

$$T.S. = \frac{\bar{X}\color{blue}{_1 - \bar{X}_2} - \color{blue}{0}}{\sqrt{\color{blue}{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}} }} \hspace{.2cm} \widetilde{\tiny H_{0}} \hspace{.2cm} t_{(\nu)},$$
where $\nu$ is a really long formula you don't have to remember because R and other statistical software will compute this for you. 

--
```{r}
#t.test(x = vector_of_data_values_pop1, y = vector_of_data_values_pop2, alternative = "?")
```


---
## Inference for a single feature of two independent populations 
### Means: Two sample t test and CI 

A $(1-\alpha)\times 100\%$ CI for an unknown mean, $\mu$, is 
$$\bar{x}_{obs,\color{blue}{1}} \color{blue}{- \bar{x}_{obs, 2}}  \pm \left(t_{\alpha/2}^* \times \sqrt{\frac{s^2_{obs\color{blue}{,pool}}}{n}}\right),$$
where $t_{\alpha/2}^*$ is the lower $\alpha/2^{th}$ quantile of a $t_{(\color{blue}{n_1 + n_2-2})}$ distribution and 
$$s_{pool}^2 = \frac{(n_1 -1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 -2}.$$
--
```{r}
#t.test(x = vector_of_data_values, y = vector_of_data_values_pop2, conf.level = ?)
```


---
## Inference for a single feature of two *dependent* populations 
## Means: Paired t test and CI for the difference in means 


**Idea:** The strong dependency between these two populations suggests that we treat these paired observations as actually coming from a common population. Then, all we need to do is some data *pre-processing*: subtract the paired observations from one another to create a single variable represented the difference in means and then treat this as a one-sample t procedure for a single population mean. 

--
This means, depending on how our data is structured we may use 
```{r}
#t.test(x = vector_of_data_values_group1, y = vector_of_data_values_group2, paired=TRUE, alternative="?")
```

or
```{r}
#t.test(x = vector_of_differences, alternative="?")
```

---
## Inference for a single feature of two *dependent* populations 
## Means: Paired t test and CI for the difference in means 

**Common examples\* **


* <font size="2">A person is matched with a similar person. For example, a person is matched to another person with a similar intelligence (IQ scores, for example) to compare the effects of two educational programs on test scores.</font>

* <font size="2">Before and after studies. For example, a person is weighed, and then put on a diet, and weighed again.</font>

* <font size="2">A person serves as his or her own control. For example, a person takes an asthma drug called GoodLungs to assess the improvement on lung function, has a period of 8-weeks in which no drugs are taken (known as a washout period), and then takes a second asthma drug called EvenBetterLungs to again assess the improvement on lung function.</font>

<font size="2">This procedure (a paired t-test) makes the assumption that the *variance* of the first population matches that of the second population.</font>

.footnote[\* Source: https://online.stat.psu.edu/stat415/lesson/3/3.3]



---
## Looking Ahead
### Final Project 

  - The deadline for the rough draft of your project report has been extended (Nov 30 for individual projects, Dec 1 for individual projects). Your final report and posters are due on Dec 7. 

  - The last day of class you will have 5 minutes to present your final project to the class. Bring your poster and assign a person to be the reporter/presenter. The remainder of the class will be time to explore other peoples projects and ask questions about them. Each person will have a questionnaire to fill out for another project to encourage everyone to explore another project and explain their own.  
  
  - Every group member should contribute to the report or to the poster, not just the individuals responsible for printing or submitting them. By contribute I mean, write something, or create an image or plot, or find relevant sources, etc.
  
  

---
## Looking ahead 

* Next class

  - Test 2 will be handed back to you for corrections which are due on Friday, Dec 3rd.
  
  - We will cover how to conduct the different Chi-square procedures in R and practice determining which procedure to use for different scenarios. 

  - Last reading assignment: Ch 21 and 22 (5th edition) 
  
  - Take a look at our [course calendar](https://docs.google.com/document/d/1d8kF77EoqvAgjfTyNRDUF3HOJvxFu9IQ2JJwpem9B_8/edit#heading=h.ijnwiall66zb) to make sure you are aware of the adjusted deadlines
  
* Homework

  - HW 7 will is due this Friday by 6pm. Office hours start after class and last until 12:30pm today.

  - HW 8 will be due over Thanksgiving break. This will involve practice setting up, conducting, and interpreting the results of the different inferential methods from HW 7 Problem 1. It will be posted tomorrow. 

  - Your last HW assignment, HW 9, will be different from the others and will be graded entirely for completion and is worth $15$ HW points. 
