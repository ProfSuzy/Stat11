<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introducing common statistical methods</title>
    <meta charset="utf-8" />
    <meta name="author" content="STAT 011 with Prof Suzy" />
    <script src="week11-part2_files/header-attrs-2.14/header-attrs.js"></script>
    <link href="week11-part2_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="week11-part2_files/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Introducing common statistical methods
### STAT 011 with Prof Suzy
### Swarthmore College

---

  



&lt;style type="text/css"&gt;
pre {
  background: #FFBB33;
  max-width: 100%;
  overflow-x: scroll;
}

.scroll-output {
  height: 60%;
  overflow-y: scroll;
}

.scroll-small {
  height: 50%;
  overflow-y: scroll;
}
   
.red{color: #ce151e;}
.green{color: #26b421;}
.blue{color: #426EF0;}
&lt;/style&gt;
     
## Today 

1. Key concepts and inference for categorical variables

2. Group work on HW 7 Problem 1 

3. The math and coding details for inference about means and proportions 

4. Looking ahead  

---
## Key concepts 
### Statistical inference 

* The sampling distribution of the sample mean (or sample proportion) is a hypothetical distribution based on the idea of repeatedly obtaining a random sample from the population of interest. 

* Statistical inference requires us to have a larger population in mind.  

* The scope of the conclusions always depends on the quality of the data and the design of the study. Garbage in means garbage out, from the most basic to the most advanced statistical methods.   


---
## Inference for categorical variables  
## Chi-square procedures

* **Test of independence**: does the data suggest that one variable may be associated with another? 

--
* **Test of homogeneity**: are the different possible outcomes of a variable equally likely? 

--
* **Goodness-of-fit**: does a hypothesized probability distribution fit your data well?



---
## Group work
### HW 7 Problem 1 

**Instructions:** With this additional information, spend another `\(15\)` minutes working with your group to answer *all* of the questions on the worksheet for Class 19. 

As I walk around, feel free to ask me questions. I may listen in to your group discussion for a bit to guide your discussions. 

&lt;br&gt; 

&lt;br&gt; 

**Hint:** There may not be any parameters for some of the chi-squared tests! 

---
## Inference for means and proportions 
## When to use the t-distribution or the Normal distribution 

* For inference about proportions, always use the Normal distribution (but make sure you have enough observed "success" and "failures"!).

* For inference about means, if the sample size is large, use the Normal distribution. .blue[(Or use the t-distribution because they're essentially the same at this point!)]

* For inference about means, if the sample size is small, use the t-distribution. 

&lt;br&gt; 
--
Side note: In practice, there are sometimes alternate ways to conduct inference on differences of means or proportions when there are two populations under consideration. 


---
## Inference for a single feature of the same population 
### Proportions: One sample Z test and CI 

`$$H_0: p = p_0; \quad H_A:  \begin{cases} p \neq p_0 \\ p \leq p_0 \\  p \geq p_0 \end{cases}$$`


`$$T.S. = \frac{\hat{p}_{obs} - p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}}\hspace{.5cm} \widetilde{\tiny H_{0}}  \hspace{.5cm}  N(0,1)$$`
--

```r
#prop.test(x=?, n=?, p=?, alternative = "?")
```


---
## Inference for a single feature of the same population 
### Proportions: One sample Z test and CI 

A `\((1-\alpha)\times 100\%\)` CI for an unknown proportion, `\(p\)`, is 
`$$\hat{p}_{obs} \pm \left( z_{\alpha/2} \times \sqrt{\frac{\hat{p}_{obs}(1-\hat{p}_{obs})}{n}}\right),$$`
where `\(z_{\alpha/2}\)` is the lower `\(\alpha/2^{th}\)` quantile of a `\(N(0,1)\)` distribution. 

--

```r
#prop.test(x=?, n=?, conf.level = 1-alpha)
```

---
## Inference for a single feature of the same population 
### Means: One sample t test and CI 

`$$H_0: \mu = \mu_0; \quad H_A:  \begin{cases} \mu \neq \mu_0 \\ \mu \leq \mu_0 \\  \mu \geq \mu_0 \end{cases}$$`

`$$T.S. = \frac{\bar{X} - \mu_0}{\sqrt{\frac{s^2}{n}}} \hspace{.2cm} \widetilde{\tiny H_{0}} \hspace{.2cm} t_{(n-1)}.$$`

--

```r
#t.test(x = vector_of_data_values, alternative = "?", mu = ?)
```

---
## Inference for a single feature of the same population 
### Means: One sample t test and CI 

A `\((1-\alpha)\times 100\%\)` CI for an unknown mean, `\(\mu\)`, is 
`$$\bar{x}_{obs} \pm \left(t^*_{\alpha/2} \times \sqrt{\frac{s^2_{obs}}{n}}\right),$$`
where `\(t^*_{\alpha/2}\)` is the lower `\(\alpha/2^{th}\)` quantile of a `\(t_{(n-1)}\)` distribution. 

--

```r
#t.test(x = vector_of_data_values, conf.level = ?)
```

---
## Inference for a single feature of the same population 
### Means: One sample t test and CI 

.scroll-output[
**Note:** Because the input must be a vector of observed data values, we must specifically extract these variables from our data object (`tibble`) using the dollar sign: 

```r
mytibble = tibble(varb1 = rnorm(5), varb2 = rt(5, df=2))
mytibble$varb1 
```

```
## [1]  0.3355044 -0.9790028 -1.3738372  0.3034958  0.1644497
```

Hence a t-test for the mean of the population from whence we obtained `varb1` may be

```r
t.test(x = mytibble$varb1, mu=0, conf.level = 0.98)
```

```
## 
## 	One Sample t-test
## 
## data:  mytibble$varb1
## t = -0.85987, df = 4, p-value = 0.4383
## alternative hypothesis: true mean is not equal to 0
## 98 percent confidence interval:
##  -1.660202  1.040446
## sample estimates:
## mean of x 
## -0.309878
```
]


---
## Inference for a single feature of two independent populations 
### Proportions: Two sample Z test and CI 

`$$H_0: p\color{blue}{_1 - p_2} = \color{blue}{0}; \quad H_A:  \begin{cases} p\color{blue}{_1 - p_2} \neq \color{blue}{0} \\ p\color{blue}{_1 - p_2} \leq \color{blue}{0} \\  p\color{blue}{_1 - p_2} \geq \color{blue}{0} \end{cases}$$`


`$$T.S. = \frac{\hat{p}\color{blue}{_1 - \hat{p}_2} - \color{blue}{0}}{\sqrt{p\color{blue}{_{pool}}(1-p\color{blue}{_{pool}})\color{blue}{\frac{1}{n_1}  + \frac{1}{n_2}}}}\hspace{.5cm} \widetilde{\tiny H_{0}}  \hspace{.5cm}  N(0,1),$$`
where `\(p_{pool} = \frac{\text{total number of observed successes}}{n_1 + n_2}.\)`

--

```r
#prop.test(x=c(number_of_successes_pop1, number_of_successes_pop2), n=c(n1, n2), alternative = "?")
```

---
## Inference for a single feature of two independent populations 
### Proportions: Two sample Z test and CI 

A `\((1-\alpha)\times 100\%\)` CI for an unknown proportion, `\(p\)`, is 
`$$\hat{p}_{obs\color{blue}{,1}} - \color{blue}{\hat{p}_2} \pm \left( z_{\alpha/2}^* \times \sqrt{ \color{blue}{ \frac{\hat{p}_{obs,1}(1-\hat{p}_{obs,1})}{n_1} + \frac{\hat{p}_{obs,2}(1-\hat{p}_{obs,2})}{n_2}  } }\right),$$`
where `\(z_{\alpha/2}^*\)` is the lower `\(\alpha/2^{th}\)` quantile of a `\(N(0,1)\)` distribution. 

--

```r
#prop.test(x=c(number_of_successes_pop1, number_of_successes_pop2), n=c(n1, n2), conf.level = ?)
```

---
## Inference for a single feature of two independent populations 
### Means: Two sample t test and CI 


`$$H_0: \mu\color{blue}{_1 - \mu_2} = \color{blue}{0} \quad H_A:  \begin{cases} \mu\color{blue}{_1 - \mu_2} \neq \color{blue}{0} \\ \mu\color{blue}{_1 - \mu_2} \leq \color{blue}{0} \\  \mu\color{blue}{_1 - \mu_2} \geq \color{blue}{0} \end{cases}$$`

`$$T.S. = \frac{\bar{X}\color{blue}{_1 - \bar{X}_2} - \color{blue}{0}}{\sqrt{\color{blue}{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}} }} \hspace{.2cm} \widetilde{\tiny H_{0}} \hspace{.2cm} t_{(\nu)},$$`
where `\(\nu\)` is a really long formula you don't have to remember because R and other statistical software will compute this for you. 

--

```r
#t.test(x = vector_of_data_values_pop1, y = vector_of_data_values_pop2, alternative = "?")
```


---
## Inference for a single feature of two independent populations 
### Means: Two sample t test and CI 

A `\((1-\alpha)\times 100\%\)` CI for an unknown mean, `\(\mu\)`, is 
`$$\bar{x}_{obs,\color{blue}{1}} \color{blue}{- \bar{x}_{obs, 2}}  \pm \left(t_{\alpha/2}^* \times \sqrt{\frac{s^2_{obs\color{blue}{,pool}}}{n}}\right),$$`
where `\(t_{\alpha/2}^*\)` is the lower `\(\alpha/2^{th}\)` quantile of a `\(t_{(\color{blue}{n_1 + n_2-2})}\)` distribution and 
`$$s_{pool}^2 = \frac{(n_1 -1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 -2}.$$`
--

```r
#t.test(x = vector_of_data_values, y = vector_of_data_values_pop2, conf.level = ?)
```


---
## Inference for a single feature of two *dependent* populations 
## Means: Paired t test and CI for the difference in means 


**Idea:** The strong dependency between these two populations suggests that we treat these paired observations as actually coming from a common population. Then, all we need to do is some data *pre-processing*: subtract the paired observations from one another to create a single variable represented the difference in means and then treat this as a one-sample t procedure for a single population mean. 

--
This means, depending on how our data is structured we may use 

```r
#t.test(x = vector_of_data_values_group1, y = vector_of_data_values_group2, paired=TRUE, alternative="?")
```

or

```r
#t.test(x = vector_of_differences, alternative="?")
```

---
## Inference for a single feature of two *dependent* populations 
## Means: Paired t test and CI for the difference in means 

**Common examples\* **


* &lt;font size="2"&gt;A person is matched with a similar person. For example, a person is matched to another person with a similar intelligence (IQ scores, for example) to compare the effects of two educational programs on test scores.&lt;/font&gt;

* &lt;font size="2"&gt;Before and after studies. For example, a person is weighed, and then put on a diet, and weighed again.&lt;/font&gt;

* &lt;font size="2"&gt;A person serves as his or her own control. For example, a person takes an asthma drug called GoodLungs to assess the improvement on lung function, has a period of 8-weeks in which no drugs are taken (known as a washout period), and then takes a second asthma drug called EvenBetterLungs to again assess the improvement on lung function.&lt;/font&gt;

&lt;font size="2"&gt;This procedure (a paired t-test) makes the assumption that the *variance* of the first population matches that of the second population.&lt;/font&gt;

.footnote[\* Source: https://online.stat.psu.edu/stat415/lesson/3/3.3]


  
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create();
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
